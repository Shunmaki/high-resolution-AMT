{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7ae38a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebooks/maki/high-resolution-AMT\n"
     ]
    }
   ],
   "source": [
    "# cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bf4a390",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join('..', '/notebooks/maki/high-resolution-AMT/utils'))\n",
    "import numpy as np\n",
    "import time\n",
    "import librosa\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from utilities import pad_truncate_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e2eff5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_data_to_device(x, device):\n",
    "    if 'float' in str(x.dtype):\n",
    "        x = torch.Tensor(x)\n",
    "    elif 'int' in str(x.dtype):\n",
    "        x = torch.LongTensor(x)\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "    return x.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95d1d894",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_to_dict(dict, key, value):\n",
    "    \n",
    "    if key in dict.keys():\n",
    "        dict[key].append(value)\n",
    "    else:\n",
    "        dict[key] = [value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89cdf4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_dataloader(model, dataloader, batch_size, return_target=True):\n",
    "    \"\"\"Forward data generated from dataloader to model.\n",
    "    Args:\n",
    "      model: object\n",
    "      dataloader: object, used to generate mini-batches for evaluation.\n",
    "      batch_size: int\n",
    "      return_target: bool\n",
    "    Returns:\n",
    "      output_dict: dict, e.g. {\n",
    "        'frame_output': (segments_num, frames_num, classes_num),\n",
    "        'onset_output': (segments_num, frames_num, classes_num),\n",
    "        'frame_roll': (segments_num, frames_num, classes_num),\n",
    "        'onset_roll': (segments_num, frames_num, classes_num),\n",
    "        ...}\n",
    "    \"\"\"\n",
    "\n",
    "    output_dict = {}\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    for n, batch_data_dict in enumerate(dataloader):\n",
    "        \n",
    "        batch_waveform = move_data_to_device(batch_data_dict['waveform'], device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            batch_output_dict = model(batch_waveform)\n",
    "\n",
    "        for key in batch_output_dict.keys():\n",
    "            if '_list' not in key:\n",
    "                append_to_dict(output_dict, key, \n",
    "                    batch_output_dict[key].data.cpu().numpy())\n",
    "\n",
    "        if return_target:\n",
    "            for target_type in batch_data_dict.keys():\n",
    "                if 'roll' in target_type or 'reg_distance' in target_type or \\\n",
    "                    'reg_tail' in target_type:\n",
    "                    append_to_dict(output_dict, target_type, \n",
    "                        batch_data_dict[target_type])\n",
    "\n",
    "    for key in output_dict.keys():\n",
    "        output_dict[key] = np.concatenate(output_dict[key], axis=0)\n",
    "    \n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1af928d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(model, x, batch_size):\n",
    "    \"\"\"Forward data to model in mini-batch. \n",
    "    \n",
    "    Args: \n",
    "      model: object\n",
    "      x: (N, segment_samples)\n",
    "      batch_size: int\n",
    "    Returns:\n",
    "      output_dict: dict, e.g. {\n",
    "        'frame_output': (segments_num, frames_num, classes_num),\n",
    "        'onset_output': (segments_num, frames_num, classes_num),\n",
    "        ...}\n",
    "    \"\"\"\n",
    "    \n",
    "    output_dict = {}\n",
    "    device = next(model.parameters()).device\n",
    "    \n",
    "    pointer = 0\n",
    "    while True:\n",
    "        if pointer >= len(x):\n",
    "            break\n",
    "\n",
    "        batch_waveform = move_data_to_device(x[pointer : pointer + batch_size], device)\n",
    "        pointer += batch_size\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            batch_output_dict = model(batch_waveform)\n",
    "\n",
    "        for key in batch_output_dict.keys():\n",
    "            # if '_list' not in key:\n",
    "            append_to_dict(output_dict, key, batch_output_dict[key].data.cpu().numpy())\n",
    "\n",
    "    for key in output_dict.keys():\n",
    "        output_dict[key] = np.concatenate(output_dict[key], axis=0)\n",
    "\n",
    "    return output_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
